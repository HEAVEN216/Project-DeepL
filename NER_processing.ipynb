{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiền xử lý dữ liệu cho MODEL NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import spacy \n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pd.set_option(\"display.max_rows\", 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc tệp CSV\n",
    "file_path = \"D:/Project DeepL/Project-DeepL/cleaned_output_no_abnormal.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Thiết lập số lượng dòng mỗi tệp nhỏ\n",
    "chunk_size = 250\n",
    "\n",
    "# Duyệt qua dữ liệu và lưu từng phần nhỏ vào các tệp CSV riêng biệt\n",
    "for i in range(0, len(data), chunk_size):\n",
    "    # Chia dữ liệu\n",
    "    chunk = data[i:i+chunk_size]\n",
    "    # Lưu thành tệp CSV nhỏ\n",
    "    chunk.to_csv(f\"D:/Project DeepL/Project-DeepL/cleaned_output_part_{i//chunk_size + 1}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned_output_part_1.csv')\n",
    "\n",
    "# Basic preprocessing\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess Vietnamese text for NER\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['processed_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Custom NER labeling function\n",
    "def custom_ner_labeling(text):\n",
    "    \"\"\"\n",
    "    Custom NER labeling for Vietnamese reviews\n",
    "    Identify key entities:\n",
    "    - PRODUCT: Product types or specific product names\n",
    "    - COLOR: Color mentions\n",
    "    - QUALITY: Quality-related terms\n",
    "    - DELIVERY: Delivery-related terms\n",
    "    \"\"\"\n",
    "    entities = []\n",
    "    \n",
    "    # Color detection\n",
    "    color_keywords = ['đen', 'trắng', 'hồng', 'xanh', 'đỏ', 'xám', 'vàng', 'tím']\n",
    "    for color in color_keywords:\n",
    "        if color in text:\n",
    "            start = text.index(color)\n",
    "            entities.append((start, start+len(color), 'COLOR'))\n",
    "    \n",
    "    # Product type detection\n",
    "    product_keywords = ['áo', 'quần', 'váy', 'giày', 'son', 'kem', 'phấn', 'túi']\n",
    "    for product in product_keywords:\n",
    "        if product in text:\n",
    "            start = text.index(product)\n",
    "            entities.append((start, start+len(product), 'PRODUCT'))\n",
    "    \n",
    "    # Quality-related detection\n",
    "    quality_keywords = ['chất lượng', 'mỏng', 'dày', 'tệ', 'đẹp', 'xấu', 'cũ']\n",
    "    for quality in quality_keywords:\n",
    "        if quality in text:\n",
    "            start = text.index(quality)\n",
    "            entities.append((start, start+len(quality), 'QUALITY'))\n",
    "    \n",
    "    # Delivery-related detection\n",
    "    delivery_keywords = ['giao hàng', 'chậm', 'sai', 'nhanh']\n",
    "    for delivery in delivery_keywords:\n",
    "        if delivery in text:\n",
    "            start = text.index(delivery)\n",
    "            entities.append((start, start+len(delivery), 'DELIVERY'))\n",
    "    \n",
    "    return entities\n",
    "\n",
    "# Prepare training data\n",
    "def prepare_spacy_training_data(texts, labels):\n",
    "    \"\"\"\n",
    "    Prepare training data for spaCy NER model\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        train_data.append((text, {'entities': label}))\n",
    "    return train_data\n",
    "\n",
    "# Generate annotated dataset\n",
    "df['ner_labels'] = df['processed_review'].apply(custom_ner_labeling)\n",
    "\n",
    "# Split the data\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['processed_review'], \n",
    "    df['ner_labels'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Prepare training data\n",
    "train_data = prepare_spacy_training_data(train_texts, train_labels)\n",
    "\n",
    "# Create a blank Vietnamese language model\n",
    "nlp = spacy.blank(\"vi\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "\n",
    "# Add labels to the NER model\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Training the NER model\n",
    "from spacy.training import Example\n",
    "\n",
    "# Initialize the DocBin for training\n",
    "db = DocBin()\n",
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    db.add(example.reference)\n",
    "\n",
    "# Save the training data\n",
    "db.to_disk(\"./train.spacy\")\n",
    "\n",
    "# Basic model configuration\n",
    "config = {\n",
    "    \"threshold\": 0.5,\n",
    "    \"model\": {\n",
    "        \"@architectures\": \"spacy.TransitionBasedParser.v1\",\n",
    "        \"hidden_width\": 64,\n",
    "        \"max_action\": 100\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"NER Preprocessing and Initial Model Setup Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
